{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artifical Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Yapay sinir ağı (ANN), insan beyninin çalışma şeklini taklit etmek için tasarlanmış bir yapay zeka modelidir. Bir yapay sinir ağı, birçok basit birimden oluşur ve her bir birim bir \"nöron\" olarak adlandırılır. Bu nöronlar, birbirleriyle bağlantılı katmanlarda düzenlenir.\n",
    "\n",
    "Yapay sinir ağları, veri içindeki karmaşık ilişkileri öğrenmek için kullanılır. Örneğin, bir resimdeki bir nesneyi tanımak veya bir metni sınıflandırmak gibi görevlerde kullanılabilirler. Bir yapay sinir ağı, verileri girdi katmanından alır, ardından gizli katmanlardan geçirir ve son olarak çıktı katmanında bir sonuç üretir.\n",
    "\n",
    "Yapay sinir ağlarının eğitimi, birçok örnekle yapılan tekrarlı bir süreçtir. Model, gerçek sonuçlarla karşılaştırılarak hatalarını azaltmak için ayarlanır. Bu süreçte, ağın ağırlıkları ve önyargıları gibi parametreleri güncellenir.\n",
    "\n",
    "Yapay sinir ağlarının avantajlarından biri, karmaşık veri setlerinde iyi performans göstermeleridir. Ancak, büyük veri setleri ve karmaşık yapılar gerektirebilirler, bu da eğitim sürecinin zaman almasına neden olabilir.\n",
    "\n",
    "Özetlemek gerekirse, yapay sinir ağları, insan beyninin işlevselliğinden ilham alarak karmaşık problemleri çözmek için kullanılan bir yapay zeka modelidir. Verileri işlerken ve öğrenirken, bu ağlar karmaşık ilişkileri öğrenir ve genellikle yüksek doğrulukla sonuçlar üretebilirler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lojistik regresyon sınıflandırmada iyidir ancak karmaşıklık (doğrusal olmayanlık) arttıkça, modelin doğruluğu azalır.\n",
    "- Bu nedenle, modelin karmaşıklığını artırmamız gerekiyor.\n",
    "- Modelin karmaşıklığını artırmak için daha fazla doğrusal olmayan fonksiyonu gizli katmana eklememiz gerekiyor.\n",
    "- Yapay sinir ağından beklediğimiz şey, karmaşıklık arttıkça daha fazla gizli katman kullanmak ve modelimizin daha iyi uyum sağlamasıdır. Sonuç olarak, doğruluk artar.\n",
    "- **Yapay Sinir Ağı Adımları:**\n",
    "    1. Kütüphaneleri İçe Aktarma\n",
    "        - Size göstermek için tekrar içe aktarıyorum, ancak aslında bunları önceki bölümlerde içe aktardık.\n",
    "    2. Veri Kümesini Hazırlama\n",
    "        - Tamamen önceki bölümdekiyle aynıdır (lojistik regresyon).\n",
    "        - Aynı veri kümesini kullandığımız için sadece train_loader ve test_loader'a ihtiyacımız var.\n",
    "        - Aynı batch boyutunu, epoch ve iterasyon sayılarını kullanıyoruz.\n",
    "    3. Yapay Sinir Ağı Modeli Oluşturma\n",
    "        - 3 gizli katman ekliyoruz.\n",
    "        - Çeşitlilik için ReLU, Tanh ve ELU aktivasyon fonksiyonlarını kullanıyoruz.\n",
    "    4. Model Sınıfını Başlatma\n",
    "        - input_dim = 28*28 # görüntünün piksel piksel boyutu\n",
    "        - output_dim = 10  # etiketler 0,1,2,3,4,5,6,7,8,9\n",
    "        - Gizli katman boyutu 150'dir. Sadece 150 olarak seçtim, bir nedeni yok. Aslında gizli katman boyutu hiperparametredir ve seçilmeli ve ayarlanmalıdır. Gizli katman boyutu için farklı değerler deneyebilir ve sonuçları gözlemleyebilirsiniz.\n",
    "        - modeli oluşturma\n",
    "    5. Kayıp Sınıfını Başlatma\n",
    "        - Cross entropy kaybı\n",
    "        - İçinde aynı zamanda softmax (lojistik fonksiyon) bulunmaktadır.\n",
    "    6. Optimizasyon Algoritmasını Başlatma\n",
    "        - SGD Optimizasyon Algoritması\n",
    "    7. Modelin Eğitilmesi\n",
    "    8. Tahmin\n",
    "- Sonuç olarak, grafikten görebileceğiniz gibi, kayıp azalırken doğruluk artıyor ve modelimiz öğreniyor (eğitiliyor).\n",
    "- Gizli katmanlara sayesinde model daha iyi öğrendi ve doğruluk (neredeyse %95) lojistik regresyon modelinin doğruluğundan daha iyidir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kütüphanelerin import edilmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verisetinin yüklenmesi ve hazirlanmasi\n",
    "Bu kısım Logistic regresyon kısmından alınmıştır açıklamalar için oraya bakabilirsiniz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r\"data/train.csv\",dtype = np.float32)\n",
    "\n",
    "targets_numpy = train.label.values\n",
    "features_numpy = train.loc[:,train.columns != \"label\"].values/255 # normalization\n",
    " \n",
    "features_train, features_test, targets_train, targets_test = train_test_split(features_numpy,\n",
    "                                                                             targets_numpy,\n",
    "                                                                             test_size = 0.2,\n",
    "                                                                             random_state = 42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresTrain = torch.from_numpy(features_train)\n",
    "targetsTrain = torch.from_numpy(targets_train).type(torch.LongTensor) # data type is long\n",
    "\n",
    "featuresTest = torch.from_numpy(features_test)\n",
    "targetsTest = torch.from_numpy(targets_test).type(torch.LongTensor) # data type is long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_iters = 10000\n",
    "num_epochs = n_iters / (len(features_train) / batch_size)\n",
    "num_epochs = int(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.utils.data.TensorDataset(featuresTrain,targetsTrain)\n",
    "test = torch.utils.data.TensorDataset(featuresTest,targetsTest)\n",
    "\n",
    "train_loader = DataLoader(train, batch_size = batch_size, shuffle = False)\n",
    "test_loader = DataLoader(test, batch_size = batch_size, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(features_numpy[51].reshape(28,28))\n",
    "plt.axis(\"off\")\n",
    "plt.title(str(targets_numpy[51]))\n",
    "plt.savefig('graph.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yapay sinir ağının oluşturulması"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Model Sınıfı Oluşturma (`class ANNModel(nn.Module)`):** Bu adımda, `ANNModel` adında bir sınıf tanımlanıyor. Bu sınıf, PyTorch'taki `nn.Module` sınıfından türetilmiştir, bu da PyTorch modeli için temel bir yapı sağlar.\n",
    "\n",
    "2. **İnit Fonksiyonu (`def __init__(self, input_dim, hidden_dim, output_dim)`):** Bu fonksiyon, sınıfın yapıcı metodu olarak bilinir. Burada, yapay sinir ağının katmanlarını ve özelliklerini tanımlarız. Girdi boyutu (`input_dim`), gizli katman boyutu (`hidden_dim`) ve çıktı boyutu (`output_dim`) gibi parametreler alır.\n",
    "\n",
    "3. **Katmanlar ve Aktivasyon Fonksiyonları Tanımlama:** Ağın katmanları ve bu katmanlarda kullanılacak aktivasyon fonksiyonları bu adımda tanımlanır. Örneğin, ilk katman olan `fc1`, giriş boyutunu (`input_dim`) ve gizli katman boyutunu (`hidden_dim`) alır. Ardından, bu katmanın ardından uygulanacak ReLU aktivasyon fonksiyonu (`relu1`) tanımlanır. Benzer şekilde, diğer katmanlar için de aynı işlem tekrarlanır.\n",
    "\n",
    "4. **İleri Yayılım Fonksiyonu (`forward(self, x)`):** Bu fonksiyon, ağın girdi verilerini alıp çıktıları üreten işlevi içerir. İleri yayılım, verinin katmanlardan geçirilmesi ve son katmandan çıktıların üretilmesi sürecidir. Her katman için tanımlanan lineer (`fc`) ve aktivasyon (`ReLU`, `Tanh`, `ELU`) işlemleri bu adımda uygulanır.\n",
    "\n",
    "Bu kod parçacığı, bir yapay sinir ağı modelinin PyTorch ile nasıl tanımlanacağını gösterir. Giriş verisi, katmanlar arasındaki işlemlerden geçirilir ve nihai olarak çıktı üretilir. Bu çıktı, modelin tahminlerini temsil eder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANNModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(ANNModel, self).__init__()\n",
    "        \n",
    "        # Linear function 1: 784 --> 150\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim) \n",
    "        # Non-linearity 1\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        # Linear function 2: 150 --> 150\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        # Non-linearity 2\n",
    "        self.tanh2 = nn.Tanh()\n",
    "        \n",
    "        # Linear function 3: 150 --> 150\n",
    "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        # Non-linearity 3\n",
    "        self.elu3 = nn.ELU()\n",
    "        \n",
    "        # Linear function 4 (readout): 150 --> 10\n",
    "        self.fc4 = nn.Linear(hidden_dim, output_dim)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Linear function 1\n",
    "        out = self.fc1(x)\n",
    "        # Non-linearity 1\n",
    "        out = self.relu1(out)\n",
    "        \n",
    "        # Linear function 2\n",
    "        out = self.fc2(out)\n",
    "        # Non-linearity 2\n",
    "        out = self.tanh2(out)\n",
    "        \n",
    "        # Linear function 2\n",
    "        out = self.fc3(out)\n",
    "        # Non-linearity 2\n",
    "        out = self.elu3(out)\n",
    "        \n",
    "        # Linear function 4 (readout)\n",
    "        out = self.fc4(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 28*28\n",
    "hidden_dim = 150 #hidden layer dim is one of the hyper parameter and it should be chosen and tuned. For now I only say 150 there is no reason.\n",
    "output_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ANNModel(input_dim, hidden_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.02\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        train = Variable(images.view(-1, 28*28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward propagation\n",
    "        outputs = model(train)\n",
    "        \n",
    "        # Calculate softmax and ross entropy loss\n",
    "        loss = error(outputs, labels)\n",
    "        \n",
    "        # Calculating gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "        if count % 50 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Predict test dataset\n",
    "            for images, labels in test_loader:\n",
    "\n",
    "                test = Variable(images.view(-1, 28*28))\n",
    "                \n",
    "                # Forward propagation\n",
    "                outputs = model(test)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs.data, 1)[1]\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += len(labels)\n",
    "\n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / float(total)\n",
    "            \n",
    "            # store loss and iteration\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "            accuracy_list.append(accuracy)\n",
    "        if count % 500 == 0:\n",
    "            # Print Loss\n",
    "            print(f'Iteration: {count}  Loss: {loss.data}  Accuracy: {accuracy} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(iteration_list,loss_list)\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"ANN: Loss vs Number of iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(iteration_list,accuracy_list,color = \"red\")\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"ANN: Accuracy vs Number of iteration\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
